# Hotel Price Classifier

<p align="center">
 <a href="#-descriÃ§Ã£o">DescriÃ§Ã£o</a>  â€¢
 <a href="#-funcionalidades">Funcionalidades</a>  â€¢ 
 <a href="#-acesso-a-aplicaÃ§Ã£o">Acesso a aplicaÃ§Ã£o</a>  â€¢ 
 <a href="#-desenvolvimento">Desenvolvimento</a>  â€¢ 
 <a href="#-execuÃ§Ã£o-local">ExecuÃ§Ã£o</a>  â€¢ 
 <a href="#-arquitetura-aws">Arquitetura AWS</a>  â€¢
 <a href="#-autor">Autor</a> 
</p>

## ğŸ“œ DescriÃ§Ã£o

Projeto tem como objetivo classificar reservas de hotel com base na faixa de preÃ§o por quarto utilizando AWS SageMaker para treinamento de modelo, AWS RDS para armazenamento de dados, e FastAPI para exposiÃ§Ã£o de uma API de prediÃ§Ã£o. O projeto Ã© containerizado utilizando Docker.

## âœ… Funcionalidades

Este projeto possui diversas funcionalidades importantes, que permitem a classificaÃ§Ã£o de reservas de hotel com base em faixas de preÃ§o por quarto, utilizando um modelo de machine learning treinado no AWS SageMaker. Aqui estÃ£o as principais funcionalidades:

**1. Carregamento e PreparaÃ§Ã£o dos Dados**

- Notebooks Jupyter: Utilizamos notebooks para carregar, explorar e preparar os dados. Isso inclui limpeza dos dados, criaÃ§Ã£o de novas features e armazenamento dos dados processados no AWS S3 e AWS RDS.
- InteraÃ§Ã£o com RDS: ConexÃ£o ao banco de dados relacional (RDS) da AWS para executar consultas SQL e manipular os dados diretamente.

**2. Treinamento do Modelo**

- AWS SageMaker: Utilizamos o AWS SageMaker para treinar um modelo de machine learning. O modelo Ã© treinado utilizando dados armazenados no S3 e a configuraÃ§Ã£o do treinamento Ã© feita nos notebooks.
- Modelo Random Forest: Escolha do algoritmo Random Forest devido Ã  sua robustez e alta performance em tarefas de classificaÃ§Ã£o.

**3. Desenvolvimento da API**

**FastAPI**
- Desenvolvemos uma API utilizando o framework FastAPI, que oferece uma interface RESTful para realizar prediÃ§Ãµes. A API Ã© configurada para carregar o modelo treinado a partir do S3.

**4. ContainerizaÃ§Ã£o**

- Docker: UtilizaÃ§Ã£o do Docker para containerizar a aplicaÃ§Ã£o, garantindo que o ambiente de execuÃ§Ã£o seja consistente em diferentes mÃ¡quinas.

**5. Deploy na AWS**
- EC2: A aplicaÃ§Ã£o pode ser implantada na AWS usando Amazon ECS, EKS ou instÃ¢ncias EC2. O uso de containers Docker facilita o deploy e a escalabilidade da aplicaÃ§Ã£o.
- AWS S3: O modelo treinado e os dados sÃ£o armazenados no Amazon S3, permitindo fÃ¡cil acesso e gerenciamento.

**Endpoint**
- /api/v1/predict: Endpoint POST que recebe um JSON com os dados da reserva e retorna a classificaÃ§Ã£o (faixa de preÃ§o).
- /: Endpoint GET que retorna uma mensagem de boas-vindas.


## ğŸ§‘â€ğŸ’» Acesso a AplicaÃ§Ã£o

**1. Para acesso a aplicaÃ§Ã£o, copie e cole no navegador:**
- PÃ¡gina inicial:
```
http://34.225.156.10
```
- PÃ¡gina para fazer prediÃ§Ãµes:
```
http://34.225.156.10/docs
```

## ğŸš€ Desenvolvimento
**ğŸ“‚ Estrutura de pastas**

 ```
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ Api
â”‚   â”‚   â”œâ”€â”€ Controllers                         
â”‚   â”‚   â”‚   â”œâ”€â”€ home_controller.py                # Controlador para a rota principal da API, respondendo com uma mensagem de boas-vindas.
â”‚   â”‚   â”‚   â””â”€â”€ prediction_controller.py          # Controlador para a rota de prediÃ§Ã£o, gerenciando a lÃ³gica de receber dados de entrada e retornar a prediÃ§Ã£o.
â”‚   â”‚   â”œâ”€â”€ Models
â”‚   â”‚   â”‚   â””â”€â”€ prediction_model.py               # Modelo de dados utilizado na API, definindo a estrutura dos dados de entrada para a prediÃ§Ã£o.
â”‚   â”‚   â”œâ”€â”€ Service                                
â”‚   â”‚   â”‚   â””â”€â”€ prediction_service                # ServiÃ§o para carregar o modelo treinado do S3 e realizar prediÃ§Ãµes.
â”‚   â”‚   â”œâ”€â”€ main.py                               # Ponto de entrada da aplicaÃ§Ã£o FastAPI
â”‚   â”‚   â”œâ”€â”€ requeriments.txt                      # Lista de dependÃªncias do Python
â”‚   â”‚   â”œâ”€â”€ .env                                  # Exemplo de como colocar variÃ¡veis que serÃ£o usadas para fazer conexÃ£o com a AWS
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml                    # ConfiguraÃ§Ã£o do Docker Compose para orquestrar a aplicaÃ§Ã£o.
â”‚   â”‚   â””â”€â”€ Dockerfile                            # ConfiguraÃ§Ã£o do Docker
â”‚   â”œâ”€â”€ data_processing
â”‚   â”‚   â”œâ”€â”€ ml_training                             
â”‚   â”‚   â”‚   â””â”€â”€ .env                              # Exemplo de como colocar variÃ¡veis que serÃ£o usadas para fazer conexÃ£o com a AWS
â”‚   â”‚   â”‚   â””â”€â”€ train_model.ipynb                 # Notebooks Jupyter para desenvolvimento e treinamento dos dados
â”‚   â”‚   â”‚   â””â”€â”€ requeriments.txt                  # Lista de dependÃªncias do Python.
â”‚   â”‚   â”œâ”€â”€ database_interaction
â”‚   â”‚   â”‚   â””â”€â”€ .env                              # Exemplo de como colocar variÃ¡veis que serÃ£o usadas para fazer conexÃ£o com a AWS
â”‚   â”‚   â”‚   â””â”€â”€ data-processing_rds-upload.ipynb  # Notebook para interaÃ§Ã£o com RDS, incluindo conexÃ£o ao banco de dados, busca de arquivo e preparaÃ§Ã£o inicial dos dados
â”‚   â”‚   â”‚   â””â”€â”€ requeriments.txt                  # Lista de dependÃªncias do Python.
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


 ```
**âš™ï¸ Tecnologias Utilizadas**
- Python: Linguagem de programaÃ§Ã£o principal.
- FastAPI: Framework para desenvolvimento da API.
- AWS SageMaker: ServiÃ§o da AWS para treinamento e deploy de modelos de machine learning.
- AWS S3: Armazenamento de dados e modelos.
- AWS RDS: Banco de dados relacional para armazenamento dos dados.
- Amazon EC2: InstÃ¢ncias de computaÃ§Ã£o na nuvem.
- Amazon ECR: RepositÃ³rio de imagens Docker.
- Docker: Ferramenta de containerizaÃ§Ã£o.
- Docker Compose: OrquestraÃ§Ã£o de containers.


## ğŸ’» ExecuÃ§Ã£o local

**PrÃ©-requisitos** : 
- `Conta na AWS com permissÃµes para SageMaker, S3, EC2, ECR e RDS`
- `Docker`
- `Python 3.9 ou superior`
- `Jupyter Notebook`

- **Clone o repositÃ³rio:**
```
git clone https://github.com/gabrielvavelar/Hotel-Price-Classifier.git
 ```

- **NÃ£o esqueÃ§a de preencher os arquivos .env com o que Ã© solicitado.**

- **Passos para executar o treinamento:**

- **Entre com suas credenciais utilizando o AWS Configure.**

- **Entre na pasta data_processing:**

```
cd data_processing  
```
- **Crie o ambiente virtual para o gerenciamento de pacotes e ative, exemplo utilizando conda:**

```
conda create -p env python=3.10
conda activate env/\
```
-  **Entre na pasta database_interaction:**

```
cd database_interaction
```
- **Instale todos os pacotes listados para uso das bibliotecas:**

```
pip install -r requirements.txt 
```
- **Execute o notebook data-processing_rds-upload.ipynb**

-  **ApÃ³s a execuÃ§Ã£o do notebook, vÃ¡ para a pasta ml_training e Instale todos os pacotes listados para uso das bibliotecas:**
```
ml_training
pip install -r requirements.txt 
```
- **Execute o train_model.ipynb**

**Passos para executar a API**
- **Entre na pasta api:**

```
cd api  
```
- **Crie o ambiente virtual para o gerenciamento de pacotes e ative, exemplo utilizando conda:**

```
conda create -p env python=3.10
conda activate env/\
```
- **Instale todos os pacotes listados para uso das bibliotecas:**

```
pip install -r requirements.txt 
```
- **Excute a api:**

```
python main.py 
```
- **Ou caso prefira executar pelo docker:**
 ```
docker-compose up
 ```

- **Acesse a aplicaÃ§Ã£o localmente:**
Abra o navegador e vÃ¡ para http://localhost:8000/docs


## ğŸŒ Arquitetura AWS
A arquitetura AWS deste projeto integra vÃ¡rios serviÃ§os da AWS para criar uma soluÃ§Ã£o de machine learning e prediÃ§Ã£o. A utilizaÃ§Ã£o de SageMaker, S3, RDS, FastAPI, Docker e EC2 permite que a aplicaÃ§Ã£o seja escalÃ¡vel, eficiente e fÃ¡cil de gerenciar. Cada componente foi escolhido para otimizar o desempenho e a escalabilidade, garantindo que o sistema possa lidar com grandes volumes de dados e fornecer prediÃ§Ãµes em tempo real.

<img src="assets/Architecture.jpg" height="400" >

## ğŸ‘¤ Autor
- [Gabriel Venancio de Avelar](https://github.com/gabrielvavelar)

